---
marp: true
title: Mysteries of parallelization
size: 4:3
paginate: true

theme: default

style: |
  section {
    background-color: #fff;
    justify-content: normal;
  }

  section.lead {
    background-color: #fff;
    justify-content: center;
  }

  section.lead h1, section.lead h2, section.lead h3, section.lead h4{
    text-align: center;
  }

  section.lead p {
    text-align: center;
  }

  img[alt=width50] {
    display: block;
    margin-left: auto;
    margin-right: auto;
    width: 50%;
  }
  img[alt=c10em] {
    display: block;
    margin-left: auto;
    margin-right: auto;
    width: 10em;
  }
  img[alt=c15em] {
    display: block;
    margin-left: auto;
    margin-right: auto;
    width: 15em;
  }
  img[alt=c20em] {
    display: block;
    margin-left: auto;
    margin-right: auto;
    width: 20em;
  }

---

<!-- _paginate: false -->
<!-- _class: lead -->

# Распараллеливание массовых вычислений

</br>

### С.А.Романенко</br>

ИПМ им. М.В. Келдыша РАН, Москва<br/>
28 февраля 2021

---

<!-- _class: lead -->

## Появление новых типов вычислительных устройств<br/>:sunrise:

<br/><br/><br/>

---

## Застой в информатике

В информатике наблюдался застой где-то с середины
70-х годов.

**Причины**:

- Безраздельно доминировал один тип вычислительных устройств:
  фон-неймановская машина (ФНМ).

- Необычайная гибкость фон-неймановской машины делала жизнь
программистов слишком лёгкой. 

---

## Специфические свойства ФНМ

![c10em](single-cpu.dot.svg)

- Последовательное исполнение команд.
- Большая и однородная память.
- Данные неподвижно лежат в том месте, куда их положили.

---

## Специфические свойства ФНМ

- Последовательное исполнение команд.
  - Нет проблем с синхронизацией. Если надо решить 2 задачи, то
    решаем сначала 1-ю, а потом -- 2-ю (или наоборот).

- Большая и однородная память.
  - Из любой части программы можно в любой момент "протянуть руку" к любому
    месту памяти.
  - Данные неподвижно лежат в том месте, куда их положили. Поэтому,
    одни данные могут ссылаться на другие. А с помощью ссылок можно
    создавать сложные структуры данных (списки, деревья).

---

## Виды параллелизма

Параллелизм, это когда **много задач решаются одновременно**.

Два основных варианта:

- Данные - общие, задачи - разные.

- Данные - разные, задача - одна и та же. (= **"Массовый"
  параллелизм.**)

(Конечно, это - упрощенная картина.)

---

## Разнородные задачи

![c15em](parall_diverse_tasks.dot.svg)

Для одних и тех же данных одновременно решается много
**_разных_** задач.

(Пример - параллельная обработка многих несвязанных запросов к безе данных.)

---

## Однородные задачи

![c15em](parall_similar_tasks.dot.svg)

**_Одна и та же_** задача решается для разных данных
  (**_массовый_** параллелизм).

(Пример - повышение резкости изображения, когда одни и те же
действия выполянются для каждой точки изображения.)

---

## Параллельные вычислители

- Многопроцессорность (multiprocessing).
  - Много процессоров (на плате или в шкафу).
  - Память у процессоров, может быть, общая, а, может быть,
    и нет.
- Многоядерность (multi-core processsor).
  - Несколько процессоров (ядер) в одном чипе.
  - Память для всех ядер - общая.
- Векторность (SIMD = single instruction, multiple data).
  - Одна команда может исполняться над несколькими данными.

---

## Многопроцессорность (multiprocessing)

![c20em](multi-cpu.dot.svg)

- Много процессоров (на плате или в шкафу).
- Память у процессоров, может быть, общая, а, может быть,
  и нет.

---

## Векторность (SIMD)

SIMD = single instruction, multiple data).

![c15em](simd.dot.svg)

- Одна команда может исполняться над несколькими данными.

---

## Графический процессор (ГП, GPU)

![c15em](gpu.dot.svg)

- Много-много процессоров (PU), разбитых на группы,
  у каждой из которых есть своя быстрая память (SRAM = shared RAM).
- И есть общая для всех память (DRAM).

---

<!-- _class: lead -->

## Графический процессор -<br/>это<br>"суперкомпьютер для бедных"<br/>:grin:

<br/><br/><br/>

---

## ГП: много-много нитей (threads)

Grid -> Block -> Warp -> Thread

- Решётка (grid) состоит из блоков.
- Блок (block) состоит из жгутов/пучков.
- Жгут (warp) состоит из нитей.

А зачем нужна структуризация множества нитей?

- Чем ниже по иерархии, тем **более тесное** взаимодействие
  возможно между нитями!

---

## ГП: зачем нужна иерархия для нитей?

### Блоки

- Внутри блока возможна синхронизация нитей (барьеры).
- Внтури блока нити могут работать с быстрой общей
  (shared) памятью.

---

## ГП: зачем нужна иерархия для нитей?

### Жгуты

- Все нити внутри жгута исполняют одну и ту же команду
  (simt = single instruction - multiple threads).
  Но некоторые нити при этом могут простиивать.
- Не нужно барьерная синхронизация внутри жгута, поскольку
  управление для всех нитей и так движется синхронно.

---

## ГП: Nvidia GeForce GT 1030

 ~7000 ₽

![c20em](GeForce_GT_1030.jpg)

---

## ГП: Nvidia GeForce GT 1030

<style scoped>
  td {
    font-size1: 22pt;
    font-size: 0.80em;
    color: green;
  }
</style>

&nbsp;                        | &nbsp;
------------------------------|----------------
Device Name                   | GeForce GT 1030
Number of Multiprocessors     | 3
Max Threads Per SMP           | 2048
Maximum Threads per Block     | 1024
Warp Size                     | 32
Global Memory Size            | 2095251456
Total Constant Memory         | 65536
Total Shared Memory per Block | 49152
Registers per Block           | 65536
L2 Cache Size                 | 524288 bytes

---

## ГП - это "микро-супер-компьютер"!

- "Блоки" соответствуют "узлам".
- "Жгуты" соответствуют "процессорам" с векторными операциями
  (SIMD).

Результат - "демократизация" массового параллелизма.

Пример: компьютерная томография. Раньше это было нечто элитарное
(требовался суперкомпьютер), а теперь томограф - это шататное
оборудование...

---

## А как же программируемая логика (ПЛИС, FPGA)?

А дело в том, что ПЛ, это **не архитектура**, а **средство
реализации** различных архитектур.

- Реализовать архитектуру можно только если она уже придумана.
- Если взять одну из известных архитектур, то для неё уже есть
  готовые реализации.
- Но можно придумать новую, неслыханную архитектуру - и реализовать
  прототип с помощью ПЛ. А потом - заказать чипы.

---

## Недостатки ПЛ с точки зрения программиста

- Изобретение новых архитектур - это не программирование,
  а несколько иная специальность.
- А если использовать известную архитектуру, то реализовывать
  её через ПЛ - нецелесообразно (дорого и медленно работает).
- Компиляция программ для известных архитектур происходит
  за секунды, а синтез схем для ПЛ может тянуться часами.
  (Нечеловеческие условия работы... :grimacing:)

---

## Почему жить стало интереснее?

- Изменилась "система ценностей" в теории сложности вычислений.
  - Раньше цель состояла в уменьшении числа операции (что
    автоматически уменьшало время выполнения). А теперь,
    время выполнения и число операций (= затраты электроэнергии) -
    не одно и то же.
- Методы и алгоритмы, которые являются "хорошими" при
  последовательных вычислениях, не обязательно являются таковыми
  в случае параллельных вычислений.

---

## Что можно "распараллеливать"?

- Программу.
  - Вставляем директивы для компилятора.
  - Реорганизуем программу.

- Алгоритм.
  - Выявляем скрытый параллелизм.
  - Реорганизуем алгоритм.
  - **Заменяем на другой алгоритм.**

- Метод.
  - Изменяем или заменяем метод.

---

<!-- _class: lead -->

## Как программировать "параллельно"<br/>:question:

<br/><br/><br/>

---


```cpp
__global__
void vectorAdd(int n,
    int const *a, int const *b, int *r) {
  int i = threadIdx.x + blockDim.x * blockIdx.x;

  if (i < n) {
    r[i] = a[i] + b[i];
  }
}
```

---

## Разное

- "Встреча у фонтана".
