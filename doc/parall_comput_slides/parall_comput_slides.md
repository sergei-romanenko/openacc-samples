---
marp: true
title: Mysteries of parallelization
size: 4:3

theme: gaia
color: #000

style: |
  section {
    background-color: #fff;
  }

  section.lead h1 {
    text-align: center;
  }
  section.lead h2 {
    text-align: center;
  }
  section.lead h3 {
    text-align: center;
  }
  section.lead h4 {
    text-align: center;
  }
  section.lead p {
    text-align: center;
  }

  section p, li {
    font-size1: 22pt;
    font-size: 0.92em;
  }

  img[alt=width50] {
    display: block;
    margin-left: auto;
    margin-right: auto;
    width: 50%;
  }
  img[alt=c10em] {
    display: block;
    margin-left: auto;
    margin-right: auto;
    width: 10em;
  }
  img[alt=c15em] {
    display: block;
    margin-left: auto;
    margin-right: auto;
    width: 15em;
  }
  img[alt=c20em] {
    display: block;
    margin-left: auto;
    margin-right: auto;
    width: 20em;
  }

---

<!-- paginate: false -->
<!--- _class: lead --->

# Распараллеливание массовых вычислений

</br>

### С.А.Романенко</br>

ИПМ им. М.В. Келдыша РАН, Москва  
28 февраля 2021

---

<!-- paginate: true -->

### Застой в информатике

В информатике наблюдался застой где-то с середины
70-х годов.

Причины:

* Безраздельно доминировал один тип вычислительных устройств: фон-неймановская 
  машина (ФНМ).

* Необычайная гибкость фон-неймановской машины делала жизнь
программистов слишком лёгкой. 

---

### Специфические свойства ФНМ

![c10em](single-cpu.dot.svg)

* Последовательное исполнение команд.
* Большая и однородная память.
* Данные неподвижно лежат в том месте, куда их положили.

---

### Специфические свойства ФНМ

* Последовательное исполнение команд.
  * Нет проблем с синхронизацией. Если надо решить 2 задачи, то
    решаем сначала 1-ю, а потом -- 2-ю (или наоборот).

* Большая и однородная память.
  * Из любой части программы можно в любой момент "протянуть руку" к любому 
    месту памяти.
  * Данные неподвижно лежат в том месте, куда их положили. Поэтому,
    одни данные могут ссылаться на другие. А с помощью ссылок можно
    создавать сложные структуры данных (списки, деревья).

---

### Виды параллелизма

Параллелизм, это когда **много задач решаются одновременно**.

Два основных варианта:

* Данные - общие, задачи - разные.

* Данные - разные, задача - одна и та же. (= **"Массовый"
  параллелизм.**)

(Конечно, это - упрощенная картина.)

---

### Разнородные задачи

![c15em](parall_diverse_tasks.dot.svg)

Для одних и тех же данных одновременно решается много
**_разных_** задач.

(Пример - параллельная обработка многих несвязанных запросов к безе данных.)

---

### Однородные задачи

![c15em](parall_similar_tasks.dot.svg)

**_Одна и та же_** задача решается для разных данных.

(Пример - повышение резкости изображения, когда одни и те же
действия выполянются для каждой точки изображения.)

---

### Параллельные вычислители

* Многопроцессорность (multiprocessing).
  * Много процессоров (на плате или в шкафу).
  * Память у процессоров, может быть, общая, а, может быть,
    и нет.
* Многоядерность (multi-core processsor).
  * Несколько процессоров (ядер) в одном чипе.
  * Память для всех ядер - общая.
* Векторность (SIMD = single instruction, multiple data).
  * Одна команда может исполняться над несколькими данными.

---

### Многопроцессорность (multiprocessing)

![c20em](multi-cpu.dot.svg)

* Много процессоров (на плате или в шкафу).
* Память у процессоров, может быть, общая, а, может быть,
  и нет.

---

### Векторность (SIMD)

SIMD = single instruction, multiple data).

![c15em](simd.dot.svg)

* Одна команда может исполняться над несколькими данными.

---

### Графический процессор (ГП, GPU)

![c15em](gpu.dot.svg)

* Много-много процессоров (PU), разбитых на группы,
  у каждой из которых есть своя быстрая память (SRAM = shared RAM).
* И есть общая для всех память (DRAM).

---

### ГП: много-много нитей (threads)

Grid -> Block -> Warp -> Thread

* Решётка (grid) состоит из блоков.
* Блок (block) состоит из жгутов/пучков.
* Жгут (warp) состоит из нитей.

А зачем нужна структуризация множества нитей?

* Чем ниже по иерархии, тем **более тесное** взаимодействие
  возможно между нитями!

---

### ГП: зачем нужна иерархия для нитей?

## Блоки

* Внутри блока возможна синхронизация нитей (барьеры).
* Внтури блока нити могут работать с быстрой общей
  (shared) памятью.

---

### ГП: зачем нужна иерархия для нитей?

## Жгуты

* Все нити внутри жгута исполняют одну и ту же команду
  (simt = single instruction - multiple threads).
  Но некоторые нити при этом могут простиивать.
* Не нужно барьерная синхронизация внутри жгута, поскольку
  управление для всех нитей и так движется синхронно.

---

### А как же программируемая логика (ПЛИС, FPGA)?

А дело в том, что ПЛ, это **не архитектура**, а **средство
реализации** различных архитектур.

* Реализовать архитектуру можно только если она уже придумана.
* Если взять одну из известных архитектур, то для неё уже есть
  готовые реализации.
* Но можно придумать новую, неслыханную архитектуру - и реализовать
  прототип с помощью ПЛ. А потом - заказать чипы.

---

### Недостатки ПЛ с точки зрения программиста

* Изобретение новых архитектур - это не программирование,
а несколько иная специальность.
* А если использовать известную архитектуру, то реализовывать
её через ПЛ - нецелесообразно (дорого и медленно работает).
* Компиляция программ для известных архитектур происходит
за секунды, а синтез схем для ПЛ может тянуться часами.
(Нечеловеческие условия работы... :grimacing:)

---

### Почему жить стало интереснее?

* Изменилась "система ценностей" в теории сложности вычислений.
  * Раньше цель состояла в уменьшении числа операции (что
    автоматически уменьшало время выполнения). А теперь,
    время выполнения и число операций (= затраты электроэнергии) -
    не одно и то же.
* Методы и алгоритмы, которые являются "хорошими" при
  последовательных вычислениях, не обязательно являются таковыми
  в случае параллельных вычислений.

---

### Что можно "распараллеливать"?

* Программу.
  * Вставляем директивы для компилятора.
  * Реорганизуем программу.

* Алгоритм.
  * Выявляем скрытый параллелизм.
  * Реорганизуем алгоритм.
  * **Заменяем на другой алгоритм.**

* Метод.
  * Изменяем или заменяем метод.

---

# Разное

* "Встреча у фонтана".
* "Микро-супер-компьютер".
